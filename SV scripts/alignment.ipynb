{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3922e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mir_eval\n",
    "import collections\n",
    "import json\n",
    "from os.path import join as joinpath\n",
    "import csv\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import os, os.path, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "aa3a1114",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS/\"\n",
    "song = \"Da_po_zoriushke_4\"\n",
    "divider = \"__\"\n",
    "\n",
    "# notes file expected at: <path>/<song>/<transcriber>/<song><divider><transcriber><divider>'notes.csv'\n",
    "\n",
    "outfile_prefix = \"howmanynotes\" # filename to write out will be of the form:\n",
    "# <outfile><divider><transcriber1><divider><transcriber2>.csv and it will be written to the song folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2a4ff89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csv(notespath):\n",
    "    notes = pd.read_csv(notespath, header=None) # doesn't read headers\n",
    "\n",
    "    # remove columns beyond the first three\n",
    "    if len(notes.columns) > 3:\n",
    "        notes = notes.iloc[:,:3]\n",
    "\n",
    "    # remove headers\n",
    "    if notes.iloc[0,0]==\"TIME\":\n",
    "        notes = notes.iloc[1:,:]\n",
    "        notes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    notes.columns = ['TIME', 'VALUE', 'DURATION']\n",
    "    \n",
    "    notes['VALUE'] = notes['VALUE'].astype(float)\n",
    "    if all(notes['VALUE']%1==0):        # all integers\n",
    "        notes['VALUE'] = notes['VALUE'].astype(int)\n",
    "\n",
    "    return notes\n",
    "\n",
    "# alignment cost function\n",
    "def getOverlap(segment1, segment2):\n",
    "    return max(0, min(segment1[1], segment2[1]) - max(segment1[0], segment2[0]))\n",
    "def getOverlapCost(segment1, segment2):\n",
    "    overlap = getOverlap(segment1, segment2)\n",
    "    if overlap == 0:\n",
    "        return 1\n",
    "    len1 = segment1[1] - segment1[0]\n",
    "    len2 = segment2[1] - segment2[0]\n",
    "    return 1 - max(overlap/len1, overlap/len2)\n",
    "\n",
    "# match segment sequences with dtw\n",
    "def mydtw(series_1, series_2):\n",
    "    # copied from simpledtw, changed cost function\n",
    "\tmatrix = np.zeros((len(series_1) + 1, len(series_2) + 1))\n",
    "\tmatrix[0,:] = np.inf\n",
    "\tmatrix[:,0] = np.inf\n",
    "\tmatrix[0,0] = 0\n",
    "\tfor i, vec1 in enumerate(series_1):\n",
    "\t\tfor j, vec2 in enumerate(series_2):\n",
    "\t\t\tcost = getOverlapCost(vec1,vec2)\n",
    "\t\t\tmatrix[i + 1, j + 1] = cost + min(matrix[i, j + 1], matrix[i + 1, j], matrix[i, j])\n",
    "\tmatrix = matrix[1:,1:]\n",
    "\ti = matrix.shape[0] - 1\n",
    "\tj = matrix.shape[1] - 1\n",
    "\tmatches = []\n",
    "\tmappings_series_1 = [list() for v in range(matrix.shape[0])]\n",
    "\tmappings_series_2 = [list() for v in range(matrix.shape[1])]\n",
    "\twhile i > 0 or j > 0:\n",
    "\t\tmatches.append((i, j))\n",
    "\t\tmappings_series_1[i].append(j)\n",
    "\t\tmappings_series_2[j].append(i)\n",
    "\t\toption_diag = matrix[i - 1, j - 1] if i > 0 and j > 0 else np.inf\n",
    "\t\toption_up = matrix[i - 1, j] if i > 0 else np.inf\n",
    "\t\toption_left = matrix[i, j - 1] if j > 0 else np.inf\n",
    "\t\tmove = np.argmin([option_diag, option_up, option_left])\n",
    "\t\tif move == 0:\n",
    "\t\t\ti -= 1\n",
    "\t\t\tj -= 1\n",
    "\t\telif move == 1:\n",
    "\t\t\ti -= 1\n",
    "\t\telse:\n",
    "\t\t\tj -= 1\n",
    "\tmatches.append((0, 0))\n",
    "\tmappings_series_1[0].append(0)\n",
    "\tmappings_series_2[0].append(0)\n",
    "\tmatches.reverse()\n",
    "\tfor mp in mappings_series_1:\n",
    "\t\tmp.reverse()\n",
    "\tfor mp in mappings_series_2:\n",
    "\t\tmp.reverse()\n",
    "\t\n",
    "\treturn matches, mappings_series_1, mappings_series_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6510ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a notes file, collect segments\n",
    "def collect_segments(notespath):\n",
    "    notes = read_from_csv(notespath)\n",
    "    onsets = notes['TIME'].astype(float).to_numpy()\n",
    "\n",
    "    durations = notes['DURATION'].astype(float).to_numpy()\n",
    "    if min(durations) == 0:\n",
    "        for idx in range(len(duration)):\n",
    "            if durations[idx] == 0:\n",
    "                durations[idx] = 0.00001\n",
    "\n",
    "    offsets = np.sum([onsets, durations],axis=0)\n",
    "    if onsets[0] < 0:\n",
    "        onsets[0] = 0\n",
    "    if offsets[0] <= 0:\n",
    "        offsets[0] = 0.000001\n",
    "    segments = np.array(list(zip(onsets, offsets)))\n",
    "        \n",
    "    return segments\n",
    "\n",
    "\n",
    "# collect note clusters (where number of segments/notes differs between transcribers) from an alignment\n",
    "def get_note_clusters(segments1, segments2, mapping_1, mapping_2):\n",
    "    cluster_segments = []\n",
    "    for idx in range(len(mapping_1)):\n",
    "        if len(mapping_1[idx]) > 1:\n",
    "            start1, stop1 = segments1[idx]\n",
    "            start2 = segments2[mapping_1[idx][0]][0]\n",
    "            stop2 = segments2[mapping_1[idx][-1]][1]\n",
    "            start = min(start1, start2)\n",
    "            stop = max(stop1, stop2)\n",
    "            cluster_segments.append([start, stop])\n",
    "    for idx in range(len(mapping_2)):\n",
    "        if len(mapping_2[idx]) > 1:\n",
    "            start1, stop1 = segments2[idx]\n",
    "            start2 = segments1[mapping_2[idx][0]][0]\n",
    "            stop2 = segments1[mapping_2[idx][-1]][1]\n",
    "            start = min(start1, start2)\n",
    "            stop = max(stop1, stop2)\n",
    "            cluster_segments.append([start, stop])\n",
    "            \n",
    "    return cluster_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "489fe44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_clusters_2csv(cluster_segments, transcriber1, transcriber2):\n",
    "    df = pd.DataFrame(cluster_segments)\n",
    "    df.columns = [\"ONSET\", \"OFFSET\"]\n",
    "    df[\"DURATION\"] = df['OFFSET'] - df['ONSET']\n",
    "    df.columns = [\"ONSET\", \"OFFSET\", \"DURATION\"]\n",
    "    df = df[[\"ONSET\", \"DURATION\"]]\n",
    "\n",
    "    outfile = outfile_prefix + divider + transcriber1 + divider + transcriber2 + '.csv'\n",
    "    outpath = joinpath(path,song,outfile)\n",
    "    df.to_csv(outpath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c4289f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcribers:  ['PP', 'OV']\n",
      "note files:  ['/Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS/Da_po_zoriushke_4/PP/Da_po_zoriushke_4__PP__notes.csv', '/Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS/Da_po_zoriushke_4/OV/Da_po_zoriushke_4__OV__notes.csv']\n"
     ]
    }
   ],
   "source": [
    "# automatically detect transcribers and collect note files\n",
    "songpath = joinpath(path,song)\n",
    "transcriber_list = next(os.walk(songpath))[1]\n",
    "\n",
    "notespath_list = []\n",
    "tlist = copy.deepcopy(transcriber_list)\n",
    "\n",
    "for transcriber in tlist:\n",
    "    filename = song + divider + transcriber + divider + 'notes.csv'\n",
    "    notespath = joinpath(path,song,transcriber,filename)\n",
    "    if os.path.isfile(notespath):\n",
    "        notespath_list.append(notespath)\n",
    "    else:\n",
    "        transcriber_list.remove(transcriber)\n",
    "print(\"transcribers: \", transcriber_list)\n",
    "print(\"note files: \", notespath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "862eae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, transcriber1 in enumerate(transcriber_list[:-1]):\n",
    "    for transcriber2 in transcriber_list[count+1:]:\n",
    "\n",
    "        notespath_list = []\n",
    "        filename1 = song + divider + transcriber1 + divider + 'notes.csv'\n",
    "        filename2 = song + divider + transcriber2 + divider + 'notes.csv'\n",
    "        notespath1 = joinpath(path,song,transcriber1,filename1)\n",
    "        notespath2 = joinpath(path,song,transcriber2,filename2)\n",
    "        \n",
    "        segments1 = collect_segments(notespath1)\n",
    "        segments2 = collect_segments(notespath2)\n",
    "        \n",
    "        matches, mapping_1, mapping_2 = mydtw(segments1, segments2)\n",
    "        \n",
    "        cluster_segments = get_note_clusters(segments1, segments2, mapping_1, mapping_2)\n",
    "        \n",
    "        write_clusters_2csv(cluster_segments, transcriber1, transcriber2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9f020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
