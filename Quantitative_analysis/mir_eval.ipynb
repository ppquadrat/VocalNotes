{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c2397330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mir_eval\n",
    "import collections\n",
    "import json\n",
    "import os, os.path, copy\n",
    "import csv\n",
    "from statistics import mean\n",
    "from os.path import join as joinpath\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "517035a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store',\n",
      " 'Da_po_zoriushke_1',\n",
      " 'Da_po_zoriushke_2',\n",
      " 'Da_po_zoriushke_3',\n",
      " 'Da_po_zoriushke_4',\n",
      " 'Kak_letala_jara',\n",
      " 'Milyj_moj_zhalkij',\n",
      " 'Na_gore_na_gorke',\n",
      " 'Neumyvataja',\n",
      " 'Oj_kumushki',\n",
      " 'Proshaj_zhizn',\n",
      " 'Protocol template.xlsx',\n",
      " 'QUAN',\n",
      " 'Selo_veselo_1',\n",
      " 'Selo_veselo_2',\n",
      " 'Selo_veselo_3',\n",
      " 'Selo_veselo_4',\n",
      " 'Selo_veselo_5',\n",
      " 'Selo_veselo_6',\n",
      " 'Temno_li_na_nebe',\n",
      " 'Tsvetiki_lazorevye',\n",
      " 'Tsvety_li_moi_tsvetiki',\n",
      " 'Uzh_ja_dumala_1',\n",
      " 'Uzh_ja_dumala_2',\n",
      " 'Zhil_byl_Lazar',\n",
      " 'recordings.csv',\n",
      " 'transcribers.csv']\n"
     ]
    }
   ],
   "source": [
    "# path to ANALYSIS folder\n",
    "PATH_TO_ANALYSIS = \"/Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/\" \n",
    "from pprint import pprint\n",
    "import os\n",
    "pprint(sorted(os.listdir(PATH_TO_ANALYSIS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "87cfec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to quantitative analysis results\n",
    "PATH_TO_QUAN = joinpath(PATH_TO_ANALYSIS, \"QUAN\")\n",
    "if not os.path.isdir(PATH_TO_QUAN):\n",
    "    os.mkdir(PATH_TO_QUAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dc88ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SONG = \"\" # leave \"\" to run through all songs\n",
    "DIVIDER = \"__\"\n",
    "FILETYPE_LIST = ['notes', 'segments', 'pitches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3c4a4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils copied from the SV preparation script\n",
    "\n",
    "def construct_pathlist(transcriber_list, filetype_list, fileext_list):\n",
    "    path_list = []\n",
    "    for transcriber in transcriber_list:\n",
    "        for filetype in filetype_list:\n",
    "            for fileext in fileext_list:\n",
    "                filename = SONG + DIVIDER + transcriber + DIVIDER + filetype + fileext\n",
    "                path = joinpath(PATH_TO_ANALYSIS,SONG,transcriber,filename)\n",
    "                path_list.append(path)\n",
    "    return path_list    \n",
    "\n",
    "def construct_pathlist_existing(transcriber_list, filetype_list, fileext_list):\n",
    "    path_list = []\n",
    "    for transcriber in transcriber_list:\n",
    "        for filetype in filetype_list:\n",
    "            for fileext in fileext_list:\n",
    "                filename = SONG + DIVIDER + transcriber + DIVIDER + filetype + fileext\n",
    "                path = joinpath(PATH_TO_ANALYSIS,SONG,transcriber,filename)\n",
    "            \n",
    "                # check existence: notes.csv are mandatory, other files optional\n",
    "                if path.endswith('notes.csv'):\n",
    "                    if os.path.isfile(path):\n",
    "                        path_list.append(path)\n",
    "                    else:\n",
    "                        print(\"ERROR: file not found: %s\" %path)\n",
    "                        raise Exception\n",
    "                else: \n",
    "                    if os.path.isfile(path):\n",
    "                        path_list.append(path)\n",
    "                    #else:\n",
    "                        #print(\"WARNING: file not found: %s\" %path)\n",
    "\n",
    "    return path_list               \n",
    "\n",
    "\n",
    "# automatically detect transcribers\n",
    "def detect_transcribers(SONG):\n",
    "    songpath = joinpath(PATH_TO_ANALYSIS,SONG)\n",
    "    if not os.path.isdir(songpath):\n",
    "        print(\"File not found: \", songpath)\n",
    "        raise Exception\n",
    "    transcriber_list = next(os.walk(songpath))[1]\n",
    "    #transcriber_list = [d for d in os.listdir(songpath) if os.path.isdir(joinpath(songpath, d))]\n",
    "        \n",
    "    tlist = copy.deepcopy(transcriber_list)\n",
    "    \n",
    "    for transcriber in tlist:\n",
    "        all_files = construct_pathlist([transcriber], FILETYPE_LIST, ['.csv', '.svl'])\n",
    "        for filepath in all_files:\n",
    "            # check existence: notes.csv are mandatory, other files optional\n",
    "            if filepath.endswith('notes.csv'):\n",
    "                if not os.path.isfile(filepath):\n",
    "                    print(\"WARNING: file not found: %s, transcriber %s discarded\" %(filepath, transcriber))\n",
    "                    transcriber_list.remove(transcriber)\n",
    "                    break\n",
    "            else: \n",
    "                if not os.path.isfile(filepath):\n",
    "                    print(\"WARNING: file not found: %s\" %filepath)                       \n",
    "\n",
    "    print(\"transcribers: \", transcriber_list)\n",
    "    # if a transcriber is not found, a file is missing or a filename is misspelled\n",
    "\n",
    "    return transcriber_list\n",
    "\n",
    "\n",
    "# custom csv read\n",
    "def read_from_csv(notespath):\n",
    "    notes = pd.read_csv(notespath, header=None, on_bad_lines=lambda x: x[:-1], engine='python') # doesn't read headers\n",
    "\n",
    "    # remove columns beyond the first three\n",
    "    if len(notes.columns) > 3:\n",
    "        notes = notes.iloc[:,:3]\n",
    "\n",
    "    # remove headers\n",
    "    if notes.iloc[0,0]==\"TIME\":\n",
    "        notes = notes.iloc[1:,:]\n",
    "        notes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if len(notes.columns) == 3:\n",
    "        notes.columns = ['TIME', 'VALUE', 'DURATION']\n",
    "    else:\n",
    "        if len(notes.columns) == 2:\n",
    "            notes.columns = ['TIME', 'VALUE']\n",
    "        else:\n",
    "            raise Exception    \n",
    "    \n",
    "    notes['VALUE'] = notes['VALUE'].astype(float)\n",
    "    if all(notes['VALUE']%1==0):        # all integers\n",
    "        notes['VALUE'] = notes['VALUE'].astype(int)\n",
    "\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de8cdf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_transcriptions(notes_filename1, notes_filename2):\n",
    "    segments1, pitches1 = load_notes(notes_filename1)\n",
    "    segments2, pitches2 = load_notes(notes_filename2)\n",
    "    mir_eval.transcription.validate(segments1, pitches1, segments2, pitches2)\n",
    "    result_dict = mir_eval.transcription.evaluate(segments1, pitches1,  segments2, pitches2)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5196ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_notes(filename):\n",
    "    notes = np.genfromtxt(filename, delimiter=',', skip_header=0, usecols=(0, 1, 2))\n",
    "    onsets = notes[:, 0]\n",
    "    pitches = notes[:, 1]\n",
    "    durations = notes[:, 2]\n",
    "    if min(durations) <= 0:\n",
    "        for idx in range(len(duration)):\n",
    "            if durations[idx] <= 0:\n",
    "                durations[idx] = 0.00001\n",
    "                print(onset, duration)\n",
    "    offsets = np.sum([onsets, durations],axis=0)\n",
    "    #if onsets[0] < 0:\n",
    "    #    onsets[0] = 0\n",
    "    #if offsets[0] <= 0:\n",
    "    #    offsets[0] = 0.00001\n",
    "    segments = np.array(list(zip(onsets, offsets)))\n",
    "    return segments, pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "50436ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_transcriptions(transcriber_list):\n",
    "    results_dictofdicts = {}\n",
    "    for count, (transcriber1, transcriber2) in enumerate(itertools.combinations(transcriber_list, 2)):\n",
    "        notespath1 = construct_pathlist([transcriber1], ['notes'], ['.csv'])[0]\n",
    "        notespath2 = construct_pathlist([transcriber2], ['notes'], ['.csv'])[0]\n",
    "        results_dictofdicts[count] = compare_two_transcriptions(notespath1, notespath2)\n",
    "    save_results(results_dictofdicts, transcriber_list)\n",
    "        \n",
    "def save_results(results_dictofdicts, transcriber_list):\n",
    "    csv_outfilename = SONG + DIVIDER + \"_\".join(transcriber_list) + DIVIDER + \"quan_analysis\" + \".csv\"\n",
    "    outpath = joinpath(PATH_TO_QUAN, csv_outfilename)\n",
    "    with open(outpath, 'w') as csvfile:\n",
    "        print(\"saving \", outpath)\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        header = ['']\n",
    "        for count, (transcriber1, transcriber2) in enumerate(itertools.combinations(transcriber_list, 2)):\n",
    "            header.append(transcriber1 + ' vs ' + transcriber2)\n",
    "        header.append(\"mean\")\n",
    "        csvwriter.writerow(header)\n",
    "        for key in results_dictofdicts[0].keys():\n",
    "            row = [key]\n",
    "            results = np.array([])\n",
    "            for count, (transcriber1, transcriber2) in enumerate(itertools.combinations(transcriber_list, 2)):\n",
    "                results = np.append(results, results_dictofdicts[count][key])\n",
    "                row.append(round(results_dictofdicts[count][key],2))\n",
    "            mymean = np.mean(results)\n",
    "            row.append(round(mymean,2))\n",
    "            csvwriter.writerow(row)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4902943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quan_analysis_1song(SONG): \n",
    "    print(\"---------------\\nRunning quantitative analysis for song: \", SONG)\n",
    "    transcriber_list = detect_transcribers(SONG)\n",
    "    if len(transcriber_list) < 2:\n",
    "        print(\"WARNING: not enough transcribers\")\n",
    "\n",
    "    else: \n",
    "        compare_all_transcriptions(transcriber_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1d0e31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Running quantitative analysis for song:  Da_po_zoriushke_1\n",
      "transcribers:  ['PP', 'OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Da_po_zoriushke_1__PP_OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Da_po_zoriushke_2\n",
      "transcribers:  ['PP', 'OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Da_po_zoriushke_2__PP_OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Da_po_zoriushke_3\n",
      "transcribers:  ['PP', 'OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Da_po_zoriushke_3__PP_OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Da_po_zoriushke_4\n",
      "transcribers:  ['PP', 'OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Da_po_zoriushke_4__PP_OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Kak_letala_jara\n",
      "transcribers:  ['PP', 'OV']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Kak_letala_jara__PP_OV__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Milyj_moj_zhalkij\n",
      "transcribers:  ['PP', 'OV']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Milyj_moj_zhalkij__PP_OV__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Na_gore_na_gorke\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Na_gore_na_gorke__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Neumyvataja\n",
      "transcribers:  ['PP', 'OV']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Neumyvataja__PP_OV__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Oj_kumushki\n",
      "transcribers:  ['PP', 'OV']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Oj_kumushki__PP_OV__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Proshaj_zhizn\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Proshaj_zhizn__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  QUAN\n",
      "transcribers:  []\n",
      "WARNING: not enough transcribers\n",
      "---------------\n",
      "Running quantitative analysis for song:  Selo_veselo_1\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Selo_veselo_1__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Selo_veselo_2\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Selo_veselo_2__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Selo_veselo_3\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Selo_veselo_3__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Selo_veselo_4\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Selo_veselo_4__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Selo_veselo_5\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Selo_veselo_5__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Selo_veselo_6\n",
      "WARNING: file not found: /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/Selo_veselo_6/OV/Selo_veselo_6__OV__notes.csv, transcriber OV discarded\n",
      "WARNING: file not found: /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/Selo_veselo_6/YN/Selo_veselo_6__YN__notes.csv, transcriber YN discarded\n",
      "transcribers:  []\n",
      "WARNING: not enough transcribers\n",
      "---------------\n",
      "Running quantitative analysis for song:  Temno_li_na_nebe\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Temno_li_na_nebe__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Tsvetiki_lazorevye\n",
      "transcribers:  []\n",
      "WARNING: not enough transcribers\n",
      "---------------\n",
      "Running quantitative analysis for song:  Tsvety_li_moi_tsvetiki\n",
      "transcribers:  ['OV', 'YN']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Tsvety_li_moi_tsvetiki__OV_YN__quan_analysis.csv\n",
      "---------------\n",
      "Running quantitative analysis for song:  Uzh_ja_dumala_1\n",
      "WARNING: file not found: /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/Uzh_ja_dumala_1/PP/Uzh_ja_dumala_1__PP__notes.csv, transcriber PP discarded\n",
      "WARNING: file not found: /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/Uzh_ja_dumala_1/YN/Uzh_ja_dumala_1__YN__notes.csv, transcriber YN discarded\n",
      "transcribers:  ['OV']\n",
      "WARNING: not enough transcribers\n",
      "---------------\n",
      "Running quantitative analysis for song:  Uzh_ja_dumala_2\n",
      "WARNING: file not found: /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/Uzh_ja_dumala_2/PP/Uzh_ja_dumala_2__PP__notes.csv, transcriber PP discarded\n",
      "transcribers:  ['OV']\n",
      "WARNING: not enough transcribers\n",
      "---------------\n",
      "Running quantitative analysis for song:  Zhil_byl_Lazar\n",
      "transcribers:  ['PP', 'OV']\n",
      "saving  /Users/polinap/Yandex.Disk.localized/RESEARCH_RU/VOCAL_NOTES_PROJECT/RUSSIAN/ANALYSIS_quan/QUAN/Zhil_byl_Lazar__PP_OV__quan_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "if len(SONG) > 0:\n",
    "    quan_analysis_1song(SONG)\n",
    "else:\n",
    "    song_list = next(os.walk(PATH_TO_ANALYSIS))[1]\n",
    "    song_list.sort()\n",
    "    for SONG in song_list:\n",
    "        quan_analysis_1song(SONG)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8316e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
